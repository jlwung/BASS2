{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def read_my_file_format(filename_queue):\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    key, value = reader.read(filename_queue)\n",
    "    \n",
    "    record_defaults = [[1] for i in range(541)]\n",
    "#     print(record_defaults)\n",
    "\n",
    "    cols = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "    labels = tf.one_hot(cols[1], 2)\n",
    "    features = tf.stack(cols[2:])\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def input_pipeline(filenames, batch_size, num_epochs=None):\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        filenames, num_epochs=num_epochs, shuffle=True)\n",
    "    example, label = read_my_file_format(filename_queue)\n",
    "  # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "  #   from -- bigger means better shuffling but slower start up and more\n",
    "  #   memory used.\n",
    "  # capacity must be larger than min_after_dequeue and the amount larger\n",
    "  #   determines the maximum we will prefetch.  Recommendation:\n",
    "  #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    min_after_dequeue = 10000\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    example_batch, label_batch = tf.train.shuffle_batch(\n",
    "        [example, label], batch_size=batch_size, capacity=capacity,\n",
    "        min_after_dequeue=min_after_dequeue)\n",
    "    return example_batch, label_batch\n",
    "\n",
    "\n",
    "train_features_app, train_labels_app = input_pipeline([\"data/train_approved.csv\"], 100)\n",
    "train_features_rej, train_labels_rej = input_pipeline([\"data/train_rejected.csv\"], 100)\n",
    "train_features = tf.concat([train_features_app, train_features_rej], 0)\n",
    "train_labels = tf.concat([train_labels_app, train_labels_rej], 0)\n",
    "\n",
    "test_features, test_labels = input_pipeline([\"data/test.csv\"], 100)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "#     print( sess.run([train_features, train_labels]) )\n",
    "    \n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)\n",
    "    \n",
    "# print(\"\\nEnd.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot_5:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"Equal_3:0\", shape=(?, 2), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#define place holder\n",
    "x = tf.placeholder(tf.float32, [None, 539])\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "dense1 = tf.layers.dense(inputs=x, units=300, activation=tf.nn.relu)\n",
    "\n",
    "prediction = tf.layers.dense(inputs=dense1, units=2, activation=tf.nn.softmax)\n",
    "\n",
    "# #create a 1-level neural network\n",
    "# W = tf.Variable(tf.truncated_normal([539, 2], stddev=0.1))\n",
    "# # b = tf.Variable(tf.zeros([2]))\n",
    "# b = tf.Variable(tf.zeros([2])+0.1)\n",
    "\n",
    "# wx_b = tf.matmul(x, W)+b\n",
    "\n",
    "#激活函数，实现非线性化\n",
    "# prediction = tf.nn.relu(wx_b)\n",
    "# prediction = tf.nn.tanh(wx_b)\n",
    "# prediction = tf.nn.sigmoid(wx_b)\n",
    "# prediction = tf.nn.softmax(wx_b)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "\n",
    "#train\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#比较预测值与实际值\n",
    "correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1)) #argmax 返回沿着某个维度最大值的位置\n",
    "\n",
    "#准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "# pred_one_hot = tf.stack(tf.argmin(prediction, 1), tf.argmax(prediction, 1))\n",
    "# a = tf.argmin(prediction, 1)\n",
    "# b = tf.argmax(prediction, 1)\n",
    "# pred_one_hot = tf.transpose(tf.stack([a, b]))\n",
    "\n",
    "pred_one_hot = tf.one_hot(tf.argmax(prediction, 1), 2)\n",
    "# pred_one_hot = tf.one_hot(tf.argmax(prediction, 1), tf.shape(prediction)[0])\n",
    "print(pred_one_hot)\n",
    "\n",
    "y_sum = tf.reduce_sum(y, 0)\n",
    "\n",
    "pred_sum = tf.reduce_sum(pred_one_hot, 0)\n",
    "\n",
    "pred_int_one_hot = tf.one_hot(tf.argmax(prediction, 1), 2, off_value=2.0)\n",
    "inter = tf.equal(y, pred_int_one_hot)\n",
    "print(inter)\n",
    "\n",
    "int_sum = tf.reduce_sum(tf.cast(inter, tf.int32), 0)\n",
    "\n",
    "# correct_rej = tf.equal(tf.argmax(y, 1), tf.argmax(pred_one_hot, 1))\n",
    "# int_rej_num = tf.reduce_sum(tf.cast(correct_rej, tf.int32))\n",
    "\n",
    "# correct_app = tf.equal(tf.argmin(y, 1), tf.argmin(pred_one_hot, 1))\n",
    "# int_app_num = tf.reduce_sum(tf.cast(correct_app, tf.int32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0 train accurancy:0.635  test accurancy:0.52\n",
      "Label sum:[86. 14.] Prediction sum[54. 46.] Correct sum:[46  6]\n",
      "step:10 train accurancy:0.735  test accurancy:0.42\n",
      "Label sum:[86. 14.] Prediction sum[32. 68.] Correct sum:[30 12]\n",
      "step:20 train accurancy:0.675  test accurancy:0.22\n",
      "Label sum:[95.  5.] Prediction sum[19. 81.] Correct sum:[18  4]\n",
      "step:30 train accurancy:0.785  test accurancy:0.2\n",
      "Label sum:[94.  6.] Prediction sum[14. 86.] Correct sum:[14  6]\n",
      "step:40 train accurancy:0.715  test accurancy:0.28\n",
      "Label sum:[96.  4.] Prediction sum[26. 74.] Correct sum:[25  3]\n",
      "step:50 train accurancy:0.705  test accurancy:0.4\n",
      "Label sum:[89. 11.] Prediction sum[31. 69.] Correct sum:[30 10]\n",
      "step:60 train accurancy:0.69  test accurancy:0.26\n",
      "Label sum:[97.  3.] Prediction sum[23. 77.] Correct sum:[23  3]\n",
      "step:70 train accurancy:0.76  test accurancy:0.38\n",
      "Label sum:[94.  6.] Prediction sum[32. 68.] Correct sum:[32  6]\n",
      "step:80 train accurancy:0.74  test accurancy:0.32\n",
      "Label sum:[94.  6.] Prediction sum[26. 74.] Correct sum:[26  6]\n",
      "step:90 train accurancy:0.845  test accurancy:0.32\n",
      "Label sum:[89. 11.] Prediction sum[23. 77.] Correct sum:[22 10]\n",
      "step:100 train accurancy:0.76  test accurancy:0.37\n",
      "Label sum:[91.  9.] Prediction sum[28. 72.] Correct sum:[28  9]\n",
      "step:110 train accurancy:0.7  test accurancy:0.35\n",
      "Label sum:[95.  5.] Prediction sum[32. 68.] Correct sum:[31  4]\n",
      "step:120 train accurancy:0.69  test accurancy:0.35\n",
      "Label sum:[92.  8.] Prediction sum[27. 73.] Correct sum:[27  8]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Start populating the filename queue.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    \n",
    "    \n",
    "    for step in range(121):\n",
    "        # Retrieve a single instance:\n",
    "        batch_xs, batch_ys = sess.run([train_features, train_labels])\n",
    "#         print(batch_xs.shape, batch_ys.shape)\n",
    "#         print(batch_xs)\n",
    "    \n",
    "        sess.run(train, feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            acc_train = sess.run(accuracy, feed_dict={x:batch_xs, y:batch_ys})\n",
    "            \n",
    "            test_xs, test_ys = sess.run([test_features, test_labels])\n",
    "            pred, acc_test = sess.run([prediction, accuracy], feed_dict={x:test_xs, y:test_ys})\n",
    "            print(\"step:\" + str(step) + \" train accurancy:\" + str(acc_train) + \"  test accurancy:\" + str(acc_test))\n",
    "            \n",
    "#             y_s, p_s, rej_cor, app_cor = sess.run(\n",
    "#                 [y_sum, pred_sum, int_rej_num, int_app_num], \n",
    "#                 feed_dict={x:test_xs, y:test_ys} )\n",
    "\n",
    "            y_s, p_s, i_s = sess.run(\n",
    "                [y_sum, pred_sum, int_sum], \n",
    "                feed_dict={x:test_xs, y:test_ys} )\n",
    "                \n",
    "            print(\"Label sum:\" + str(y_s) + \" Prediction sum\" + str(p_s) + \n",
    "                  \" Correct sum:\" + str(i_s))\n",
    "                  \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
